{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e69645fe-aed1-468a-b02b-20ae36a9021e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b206f833-9f48-4a51-ab2a-449dea3f0c53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_and_extract_tar_gz_file(bucket_name, object_key, destination_folder):\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    # Create an S3 client\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    # Download the tar.gz file from S3 to a local file\n",
    "    local_tar_gz_file_path = os.path.join(destination_folder, os.path.basename(object_key))\n",
    "    print(os.path.basename(object_key))\n",
    "    s3_client.download_file(bucket_name, object_key, local_tar_gz_file_path)\n",
    "\n",
    "    # Extract the contents of the tar.gz file\n",
    "    with tarfile.open(local_tar_gz_file_path, 'r:gz') as tar:\n",
    "        tar.extractall(destination_folder)\n",
    "\n",
    "    # Remove the downloaded tar.gz file if needed\n",
    "    os.remove(local_tar_gz_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eea37a6f-e4b7-4daf-8ef0-07c6b9b8dc0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.9/site-packages (0.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.9/site-packages (4.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.9/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.4.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: diffusers in /opt/conda/lib/python3.9/site-packages (0.18.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from diffusers) (2023.6.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.9/site-packages (from diffusers) (4.13.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.2 in /opt/conda/lib/python3.9/site-packages (from diffusers) (0.16.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from diffusers) (1.23.5)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.9/site-packages (from diffusers) (9.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from diffusers) (3.12.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from diffusers) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.13.2->diffusers) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.13.2->diffusers) (4.64.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.13.2->diffusers) (2023.1.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.13.2->diffusers) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.13.2->diffusers) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata->diffusers) (3.13.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->diffusers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->diffusers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->diffusers) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->diffusers) (2022.12.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Found existing installation: accelerate 0.16.0\n",
      "Uninstalling accelerate-0.16.0:\n",
      "  Successfully uninstalled accelerate-0.16.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install safetensors\n",
    "!pip install transformers --upgrade\n",
    "!pip install diffusers\n",
    "!pip uninstall accelerate -y\n",
    "!pip install accelerate>=0.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15912108-23e1-4969-af10-06944d81ac73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script is for LoRA weights converting. It is NOT elegant, just working for temporary usage.\n",
    "\n",
    "(1) Train in diffusers, the LoRA is saved in .bin format. You can convert it to .safetensors for stable-diffusion-webui. Note that diffusers only support adding LoRA to UNet.\n",
    "\n",
    "(2) Download from other platforms such as civitai, the LoRA is saved in .safetensors. You can convert it to .bin then and load in unet directly using diffusers API.\n",
    "\n",
    "All is about weight mapping. Below are weight namings of .bin and .safetensors for a specific layer.\n",
    "\n",
    "# model layer\n",
    "# Linear(in_features=320, out_features=320, bias=False)\n",
    "pipeline.unet.down_blocks[0].attentions[0].transformer_blocks[0].attn1.to_q\n",
    "\n",
    "- .bin\n",
    "'down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.to_q_lora.up.weight' # torch.Size([320, rank])\n",
    "'down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.to_q_lora.down.weight' # torch.Size([rank, 320])\n",
    "\n",
    "- .safetensors\n",
    "'lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.lora_up.weight' # torch.Size([320, rank])\n",
    "'lora_unet_down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.lora_down.weight' # torch.Size([rank, 320])\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from safetensors.torch import load_file, save_file\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from diffusers import DPMSolverMultistepScheduler\n",
    "\n",
    "\n",
    "LORA_PREFIX_UNET = 'lora_unet'\n",
    "\n",
    "\n",
    "def convert_name_to_bin(name):\n",
    "    \n",
    "    # down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q.lora_up\n",
    "    new_name = name.replace(LORA_PREFIX_UNET+'_', '')\n",
    "    new_name = new_name.replace('.weight', '')\n",
    "    \n",
    "    # ['down_blocks_0_attentions_0_transformer_blocks_0_attn1_to_q', 'lora.up']\n",
    "    parts = new_name.split('.')\n",
    "    \n",
    "    #parts[0] = parts[0].replace('_0', '')\n",
    "    if 'out' in parts[0]:\n",
    "        parts[0] = \"_\".join(parts[0].split('_')[:-1])\n",
    "    parts[1] = parts[1].replace('_', '.')\n",
    "    \n",
    "    # ['down', 'blocks', '0', 'attentions', '0', 'transformer', 'blocks', '0', 'attn1', 'to', 'q']\n",
    "    # ['mid', 'block', 'attentions', '0', 'transformer', 'blocks', '0', 'attn2', 'to', 'out']\n",
    "    sub_parts = parts[0].split('_')\n",
    "\n",
    "    # down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q_\n",
    "    new_sub_parts = \"\"\n",
    "    for i in range(len(sub_parts)):\n",
    "        if sub_parts[i] in ['block', 'blocks', 'attentions'] or sub_parts[i].isnumeric() or 'attn' in sub_parts[i]:\n",
    "            if 'attn' in sub_parts[i]:\n",
    "                new_sub_parts += sub_parts[i] + \".processor.\"\n",
    "            else:\n",
    "                new_sub_parts += sub_parts[i] + \".\"\n",
    "        else:\n",
    "            new_sub_parts += sub_parts[i] + \"_\"\n",
    "    \n",
    "    # down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor.to_q_lora.up\n",
    "    new_sub_parts += parts[1]\n",
    "    \n",
    "    new_name =  new_sub_parts + '.weight'\n",
    "    \n",
    "    return new_name\n",
    "\n",
    "\n",
    "def safetensors_to_bin(safetensor_path, bin_path):\n",
    "    \n",
    "    bin_state_dict = {}\n",
    "    safetensors_state_dict = load_file(safetensor_path)\n",
    "        \n",
    "    for key_safetensors in safetensors_state_dict:\n",
    "        # these if are required  by current diffusers' API\n",
    "        # remove these may have negative effect as not all LoRAs are used\n",
    "        if 'text' in key_safetensors:\n",
    "            continue\n",
    "        if 'unet' not in key_safetensors:\n",
    "            continue\n",
    "        if 'transformer_blocks' not in key_safetensors:\n",
    "            continue\n",
    "        if 'ff_net' in key_safetensors or 'alpha' in key_safetensors:\n",
    "            continue\n",
    "        key_bin = convert_name_to_bin(key_safetensors)\n",
    "        bin_state_dict[key_bin] = safetensors_state_dict[key_safetensors]\n",
    "    \n",
    "    torch.save(bin_state_dict, bin_path)\n",
    "\n",
    "    \n",
    "def convert_name_to_safetensors(name):\n",
    "    \n",
    "    # ['down_blocks', '0', 'attentions', '0', 'transformer_blocks', '0', 'attn1', 'processor', 'to_q_lora', 'up', 'weight']\n",
    "    parts = name.split('.')\n",
    "    \n",
    "    # ['down_blocks', '_0', 'attentions', '_0', 'transformer_blocks', '_0', 'attn1', 'processor', 'to_q_lora', 'up', 'weight']\n",
    "    for i in range(len(parts)):\n",
    "        if parts[i].isdigit():\n",
    "            parts[i] = '_' + parts[i]\n",
    "        if \"to\" in parts[i] and \"lora\" in parts[i]:\n",
    "            parts[i] = parts[i].replace('_lora', '.lora')\n",
    "        \n",
    "    new_parts = []\n",
    "    for i in range(len(parts)):\n",
    "        if i == 0:\n",
    "            new_parts.append(LORA_PREFIX_UNET + '_' + parts[i])\n",
    "        elif i == len(parts) - 2:\n",
    "            new_parts.append(parts[i] + '_to_' + parts[i+1])\n",
    "            new_parts[-1] = new_parts[-1].replace('_to_weight', '')\n",
    "        elif i == len(parts) - 1:\n",
    "            new_parts[-1] += '.' + parts[i]\n",
    "        elif parts[i] != 'processor':\n",
    "            new_parts.append(parts[i])\n",
    "    new_name = '_'.join(new_parts)\n",
    "    new_name = new_name.replace('__', '_')\n",
    "    new_name = new_name.replace('_to_out.', '_to_out_0.')\n",
    "    return new_name\n",
    "\n",
    "\n",
    "def bin_to_safetensors(bin_path, safetensor_path):\n",
    "    \n",
    "    bin_state_dict = torch.load(bin_path)\n",
    "    safetensors_state_dict = {}\n",
    "    \n",
    "    for key_bin in bin_state_dict:\n",
    "        key_safetensors = convert_name_to_safetensors(key_bin)\n",
    "        safetensors_state_dict[key_safetensors] = bin_state_dict[key_bin]\n",
    "    \n",
    "    save_file(safetensors_state_dict, safetensor_path)\n",
    "   \n",
    "    \n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(model_id,torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8010d07-0dc1-4a5c-b7ca-8a752ffea5a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70e98bad-de67-431f-bbe1-49d01a341878",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'sagemaker-image-generation-data'\n",
    "sub_folder = \"lora_outputs/pipelines-9xo8zrlbgm2j-Lora-TrainModel-knDevfkeeA/output/\"\n",
    "object_key = sub_folder + 'model.tar.gz'  # Replace with the actual subfolder path and object key\n",
    "destination_folder = 'lora_model_multi'  # Replace with the desired destination folder path\n",
    "out_name = \"/multi.st\"\n",
    "download_and_extract_tar_gz_file(bucket_name, object_key, destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3216045a-a4a0-4da8-8cf5-0cb3bd8b2ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bin_path = destination_folder + '/pytorch_lora_weights_010000.bin'\n",
    "st_path = destination_folder + out_name\n",
    "bin_to_safetensors(bin_path, st_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380f63c4-7cd0-4e6b-907a-37ca58618c52",
   "metadata": {},
   "source": [
    "# Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9ed6026-ee10-4c91-9bdb-9c82d7b28ee6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'sagemaker-image-generation-data'\n",
    "sub_folder = \"lora_outputs/pipelines-pggertibdojo-Lora-TrainModel-Z7O308CIpk/output/\"\n",
    "object_key = sub_folder + 'model.tar.gz'  # Replace with the actual subfolder path and object key\n",
    "destination_folder = 'lora_model_single'  # Replace with the desired destination folder path\n",
    "out_name = \"/single.st\"\n",
    "download_and_extract_tar_gz_file(bucket_name, object_key, destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f237710-b503-4660-bda5-1bf8f6e96baa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bin_path = destination_folder + '/pytorch_lora_weights_010000.bin'\n",
    "st_path = destination_folder + out_name\n",
    "bin_to_safetensors(bin_path, st_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41835217-0503-4dea-a274-ea1a6d17ecc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def upload_file_to_s3(local_file_path, bucket_name, subfolder_name, s3_destination_filename=None):\n",
    "    \"\"\"\n",
    "    Uploads a local file to an S3 bucket subfolder.\n",
    "\n",
    "    Parameters:\n",
    "    local_file_path (str): The path to the local file.\n",
    "    bucket_name (str): The name of the S3 bucket.\n",
    "    subfolder_name (str): The name of the subfolder within the bucket.\n",
    "    s3_destination_filename (str): (Optional) The filename to be used in S3. If not provided, the original filename will be used.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the upload was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create an S3 client\n",
    "        s3_client = boto3.client('s3')\n",
    "\n",
    "        # Construct the S3 destination path\n",
    "        if s3_destination_filename is None:\n",
    "            s3_destination_filename = local_file_path.split('/')[-1]  # Use the original filename if not provided\n",
    "        s3_destination_path = f\"{subfolder_name}/{s3_destination_filename}\"\n",
    "\n",
    "        # Upload the file to S3\n",
    "        s3_client.upload_file(local_file_path, bucket_name, s3_destination_path)\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file to S3: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd4c6e76-4409-4f06-996a-763375898d85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage example:\n",
    "local_file_path_multi = \"lora_model_multi/multi.st\"\n",
    "local_file_path_single = \"lora_model_single/single.st\"\n",
    "bucket_name = 'sagemaker-image-generation-data'\n",
    "subfolder_name = \"lora_outputs/safetensors\"\n",
    "s3_destination_filename_multi = 'multi.st'\n",
    "s3_destination_filename_single = 'single.st'\n",
    "\n",
    "upload_file_to_s3(local_file_path_multi, bucket_name, subfolder_name, s3_destination_filename_multi)\n",
    "upload_file_to_s3(local_file_path_single, bucket_name, subfolder_name, s3_destination_filename_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a901a4bb-675e-4798-ae4a-2ec8ccbfafb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g4dn.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-1.13-gpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
